"""
Utilities for convolving families of kernels with data.

Author: Ankit N. Khambhati
Adapted from: https://github.com/pennmem/ptsa_new/blob/master/ptsa/wavelet.py
Last Updated: 2018/09/11
"""

import numpy as np
import scipy.fftpack

try:
    import pyfftw

    def fft(*args, **kwargs):
        return pyfftw.builders.fft(*args, **kwargs)()

    def ifft(*args, **kwargs):
        return pyfftw.builders.ifft(*args, **kwargs)()

    print('Using `pyfftw`.')

except ImportError as e:
    fft = scipy.fftpack.fft
    ifft = scipy.fftpack.ifft
    print('Using `scipy.fftpack`.')


def fconv(kernel, signal, boundary=None, fft=fft, ifft=ifft, interp_nan=True):
    """
    Convolve kernel bank with multidimensional signals using FFT.

    Parameters
    ----------
    kernel: np.ndarray, shape: [n_sample_1, n_kernel]
        Array of kernels (generated by `family` module)
    signal: np.ndarray, shape: [n_sample_2, n_signal]
        Multidimensional signal array (must be two dimensional)
    boundary: {None, 'mirror'}
        Specifies how to handle the boundary of the signal.
    fft/ifft: Function handles to a routine that calls fft.
        By default, this code calls a wrapper around the pyfftw module.
    interp_nan: bool
        Specifies whether to return interpolated result or to add
        NaNs back into the convolved signal.

    Returns
    -------
    arr_conv: np.ndarray, shape: [n_sample_2, n_kernel, n_signal]
    """

    # Convert to complex types
    kernel = np.asarray(kernel, dtype=complex)
    signal = np.asarray(signal, dtype=complex)

    # get the number of signals and samples in each input
    n_sample_1, n_kernel = kernel.shape
    n_sample_2, n_signal = signal.shape
    if n_sample_1 > n_sample_2:
        raise ValueError('Kernel cannot have greater length than signal.')

    # Handle boundary case
    if boundary == 'mirror':
        signal_lead = signal[:n_sample_1, :][::-1, :]
        signal_lag = signal[-n_sample_1:, :][::-1, :]
        signal = np.concatenate((signal_lead, signal, signal_lag))
        n_sample_2 = signal.shape[0]

    # Handle NaNs and Infs
    mask_nan = ~np.isfinite(signal)
    signal[mask_nan] = 0

    # Pre-allocate array
    n_s = n_sample_1 + n_sample_2
    big_shape = np.array((n_s, n_kernel))
    arr_conv = np.zeros((n_sample_2, n_kernel, n_signal), dtype=np.complex)

    # Pre-compute `FFT Kernel` and `FFT Energy`
    big_kernel = np.zeros(big_shape, dtype=complex)
    big_kernel[centered(n_s, n_sample_1), :] = kernel[:, :]
    fft_kernel = fft(np.fft.ifftshift(big_kernel, axes=0), axis=0)
    fft_energy = fft(np.fft.ifftshift(np.abs(big_kernel**2), axes=0), axis=0)

    # Iterate over each signal dimension
    for s_i in range(n_signal):

        # Convolve main signal with kernel
        big_signal = np.zeros(big_shape, dtype=complex)
        big_signal[centered(n_s, n_sample_2), :] = \
                signal[:, s_i].reshape(-1, 1)
        fft_signal = fft(big_signal, axis=0)
        fft_sigkern = fft_signal * fft_kernel

        # Handle NaN interpolation
        big_signal = 0 * np.asarray(big_signal, dtype=complex)
        big_signal[centered(n_s, n_sample_2), :] = \
                (1.0 - mask_nan[:, s_i]).reshape(-1, 1)
        fft_missing = fft(big_signal, axis=0)
        fft_missnrg = fft_missing * fft_energy
        missnrg = np.sqrt(ifft(fft_missnrg, axis=0).real)

        # Final inverse transform gives the convolution,
        # normalized by segment of valid kernel (non-NaN portion)
        sigkern_missnrg = ifft(fft_sigkern, axis=0) / missnrg
        sigkern_missnrg[missnrg < (10 * np.finfo(missnrg.dtype).eps)] = 0.0

        # Clip the convolved signal to the signal length
        arr_conv[:, :, s_i] = sigkern_missnrg[centered(n_s, n_sample_2), :]

        # Put NaN back
        if not interp_nan:
            arr_conv[mask_nan[:, s_i], :, s_i] = np.nan

    # Remove the mirrored buffer
    if boundary == 'mirror':
        arr_conv = arr_conv[n_sample_1:-n_sample_1, ...]

    return arr_conv


def centered(curr_size, new_size):
    """
    Use with convolution, return center indices for an array of a specific len.

    Parameters
    ----------
    curr_size: int
        Length of dimension to truncate in the current array.
    new_size: int
        Intended length of the dimension to truncate in the new array.

    Returns
    -------
    ind: np.ndarray, shape: (new_size,)
        Indices to excise the center portion along one dimension
        of the current array.
    """

    curr_size = int(curr_size)
    new_size = int(new_size)

    center = curr_size - (curr_size + 1) // 2
    return slice(center - (new_size) // 2, center + (new_size + 1) // 2)
